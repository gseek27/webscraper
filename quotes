import urllib2
from bs4 import BeautifulSoup

import csv
from datetime import datetime

url = ['http://quotes.toscrape.com/', 'http://quotes.toscrape.com/page/2']
web = 'http://quotes.toscrape.com/page/'

for i in range(1,10):
    site = str(web + str(i))
    print site

from unidecode import unidecode
def remove_non_ascii(text):
    return unidecode(unicode(text, encoding = "utf-8"))

data = []

for i in url:
    page = urllib2.urlopen(i)
    soup = BeautifulSoup(page, "lxml")
    auth = soup.find_all('small', attrs={'class': 'author'})
    author = auth
    quo =  soup.find_all('span', attrs={'class': 'text'})
    quote = quo
    print author
    print quote
    data.append((author, quote))

with open('index.csv', 'a') as csv_file:
    writer = csv.writer(csv_file)
    for author, quote in data:
        writer.writerow([author, quote, datetime.now()])
