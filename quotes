import urllib2
from bs4 import BeautifulSoup

import csv
from datetime import datetime

import itertools

web = 'http://quotes.toscrape.com/page/'

data = []

for i in range(1,11):
    site = str(web + str(i))
    print ''
    print site
    print ''
    page = urllib2.urlopen(site)
    soup = BeautifulSoup(page, "lxml")
    quo =  soup.find_all('span', attrs={'class': 'text'})
    auth = soup.find_all('small', attrs={'class': 'author'})
    for (q, a) in itertools.izip_longest(quo, auth):
        quo = q.text
        auth = a.text
        quote = quo.encode("ascii", "ignore")
        quote = str('"' + quote + '"')
        author = auth.encode("ascii", "ignore")
        print str(quote + ' - ' + author)
        print ''
        data.append((author, quote))

with open('index.csv', 'a') as csv_file:
    writer = csv.writer(csv_file)
    for author, quote in data:
        writer.writerow([author, quote, datetime.now()])
